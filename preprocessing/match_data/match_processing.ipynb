{
  "metadata": {
    "name": "match_processing",
    "kernelspec": {
      "language": "scala",
      "name": "spark2-scala"
    },
    "language_info": {
      "codemirror_mode": "text/x-scala",
      "file_extension": ".scala",
      "mimetype": "text/x-scala",
      "name": "scala",
      "pygments_lexer": "scala"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2,
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "import org.apache.spark.sql.expressions.Window\nval filePath \u003d \"/user/avk3358_nyu_edu/project/data\"\nvar matchDF \u003d spark.read.json(filePath)\n                        .withColumn(\"input_file\", input_file_name())\nz.show(matchDF)"
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "matchDF.count()"
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "matchDF.printSchema()"
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "matchDF.select(\"date\", \"time\").show(5)"
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "val dateConvertedDF \u003d matchDF.withColumn(\"date\", to_date(col(\"date\"), \"dd MMM yyyy\"))\n                             .withColumn(\"time\", to_timestamp(col(\"time\"), \"dd MMM yyyy HH:mm\"))"
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "dateConvertedDF.select(\"date\", \"time\").show(5)"
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "dateConvertedDF.printSchema()"
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "val trimmedDF \u003d dateConvertedDF.withColumn(\"city\", lower(trim(col(\"city\"))))\n                        .withColumn(\"country\", lower(trim(col(\"country\"))))\n                        .withColumn(\"sport\", lower(trim(col(\"sport\"))))\n                        .withColumn(\"stadium\", lower(trim(col(\"stadium\"))))\n                        .withColumn(\"tournament\", lower(trim(col(\"tournament\"))))\n                        .withColumn(\"input_file\", split(col(\"input_file\"), \"/\").getItem(7))\nval rightDF \u003d trimmedDF.withColumn(\"access_date\", to_date(split(col(\"input_file\"), \"\\\\.\").getItem(0))).drop(\"input_file\")\nz.show(rightDF)"
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "rightDF.printSchema"
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "val badTeamsDF \u003d rightDF.filter(size(col(\"teams\")) \u003e 2).select(\"teams\")\nz.show(badTeamsDF)"
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "badTeamsDF.count"
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "import scala.collection.mutable.HashSet\nimport scala.collection.mutable.ListBuffer\n \ndef modifyArray(inputArray: Array[String]): Array[String] \u003d {\n    val length \u003d inputArray.size\n    if(length \u003d\u003d 2) return inputArray\n    val table \u003d HashSet[String](\"Slo\", \"Wol\", \"Co\", \"Li\", \"Ala\", \"E\", \"Bayer Le\", \"Le Ha\", \"Ju\", \"GD Cha\")\n    val outBuffer \u003d ListBuffer[String]()\n    var i \u003d 0\n    while (i \u003c length){\n        var s \u003d inputArray(i)\n        if(s.contains(\"-\")){\n            s \u003d inputArray(i).split(\"-\")(1).trim()\n        }\n        if(table.contains(s)){\n            outBuffer +\u003d (inputArray(i)+\"v\"+inputArray(i+1)).toLowerCase()\n            i+\u003d2\n        }\n        else{\n            outBuffer +\u003d inputArray(i).toLowerCase()\n            i+\u003d1\n        }\n    }\n    return outBuffer.toArray\n}\nval modifyTeamsArray \u003d udf(modifyArray _)"
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "val updatedDF \u003d rightDF.withColumn(\"teams\", modifyTeamsArray(col(\"teams\"))).filter(size(col(\"teams\")) \u003d\u003d\u003d 2)\nz.show(updatedDF.select(\"teams\"))"
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "updatedDF.filter(size(col(\"teams\")) \u003e 2).count()"
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "updatedDF.printSchema"
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "z.show(updatedDF)"
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "updatedDF.select($\"date\", $\"teams\").distinct().count()"
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "\nval w \u003d Window.partitionBy($\"date\", $\"teams\").orderBy($\"date\".desc)\n\nval uniqueMatchesDF \u003d updatedDF.withColumn(\"rn\", row_number.over(w)).where($\"rn\" \u003d\u003d\u003d 1).drop(\"rn\")\n                                .withColumn(\"match_id\", expr(\"uuid()\"))\n                                .drop($\"access_date\")\n                                .drop($\"tickets\")\n\nz.show(uniqueMatchesDF)"
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "uniqueMatchesDF.count()"
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "uniqueMatchesDF.printSchema"
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "def getMatchesByTeams(teams: Array[String], matchesDF: org.apache.spark.sql.DataFrame): org.apache.spark.sql.DataFrame \u003d {\n    // Filter the DataFrame based on the given date and teams\n    matchesDF\n      .filter(array_contains($\"teams\", teams(0)) \u0026\u0026 array_contains($\"teams\", teams(1)))\n}"
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "val teams \u003d Array(\"Borussia Dortmund\", \"Paris Saint-Germain\")\n\nval filteredMatchesDF \u003d getMatchesByTeams(teams, uniqueMatchesDF)\n\n// Show the filtered DataFrame\nz.show(filteredMatchesDF)"
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "val columnsFromDF1 \u003d uniqueMatchesDF.columns\n\nval combinedTicketsDF \u003d updatedDF\n  .join(uniqueMatchesDF.select($\"date\", $\"teams\", $\"match_id\"), Seq(\"date\", \"teams\"), \"inner\")\n  .select(\"*\")\n\ncombinedTicketsDF.count()"
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "z.show(combinedTicketsDF)"
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "combinedTicketsDF.printSchema()"
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "import org.apache.spark.sql.functions._\n\nval explodedDF \u003d combinedTicketsDF.withColumn(\"ticket\", explode(col(\"tickets\")))\n\nval ticketDF \u003d explodedDF.select(\n  col(\"match_id\"),\n  col(\"access_date\"),\n  col(\"ticket.category\").alias(\"ticket_category\"),\n  col(\"ticket.info\").alias(\"ticket_info\"),\n  col(\"ticket.price\").alias(\"ticket_price\")\n)\n\nz.show(ticketDF)"
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "ticketDF.count"
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "import org.apache.spark.sql.types.DoubleType\n\nval updatedTicketDF \u003d ticketDF.withColumn(\"ticket_price\", regexp_replace(col(\"ticket_price\"), \"[£, ]\", \"\").cast(DoubleType))\n\nz.show(updatedTicketDF)"
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "updatedTicketDF.filter($\"ticket_price\".isNull).count()"
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "updatedTicketDF.printSchema"
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "val filteredTicketDF \u003d updatedTicketDF.withColumn(\"ticket_info\", lower(trim(regexp_replace(col(\"ticket_info\"), \"[*#-.:\u003d]\", \"\"))))\n                                .withColumn(\"ticket_category\", lower(trim(col(\"ticket_category\"))))\nz.show(filteredTicketDF)"
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "uniqueMatchesDF.printSchema"
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "filteredTicketDF.printSchema"
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "val eventOutputPath \u003d \"/user/avk3358_nyu_edu/project/data/cleaned-event-df.parquet\"\n\nuniqueMatchesDF.write.mode(\"overwrite\").parquet(eventOutputPath)"
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "val ticketOutputPath \u003d \"/user/avk3358_nyu_edu/project/data/ticket-df.parquet\"\n\nfilteredTicketDF.write.mode(\"overwrite\").parquet(ticketOutputPath)"
    }
  ]
}