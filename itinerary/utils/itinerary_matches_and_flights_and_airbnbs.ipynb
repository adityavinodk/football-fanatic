{
  "metadata": {
    "name": "Note converted from Jupyter_2JUTBCRE9",
    "kernelspec": {
      "language": "scala",
      "name": "spark2-scala"
    },
    "language_info": {
      "codemirror_mode": "text/x-scala",
      "file_extension": ".scala",
      "mimetype": "text/x-scala",
      "name": "scala",
      "pygments_lexer": "scala"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2,
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "val matchDataFilePath \u003d \"/user/avk3358_nyu_edu/project/data/cleaned-event-df.parquet\"\nvar matchDF \u003d spark.read.parquet(matchDataFilePath)"
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "z.show(matchDF)"
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "matchDF.printSchema"
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "val ticketDataFilePath \u003d \"/user/avk3358_nyu_edu/project/data/ticket-df.parquet\"\nvar ticketDF \u003d spark.read.parquet(ticketDataFilePath)"
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "z.show(ticketDF)"
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "ticketDF.printSchema"
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "def getMatchesByTeams(teams: Array[String], matchesDF: org.apache.spark.sql.DataFrame): org.apache.spark.sql.DataFrame \u003d {\n    matchesDF\n      .filter(array_contains($\"teams\", teams(0)) \u0026\u0026 array_contains($\"teams\", teams(1)))\n}"
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "val teams \u003d Array(\"Real Madrid\", \"Bayern Munich\")\n\nval filteredMatchesDF \u003d getMatchesByTeams(teams, matchDF)\n\nz.show(filteredMatchesDF)"
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "val joinedDF \u003d ticketDF\n  .join(filteredMatchesDF, filteredMatchesDF(\"match_id\") \u003d\u003d\u003d ticketDF(\"match_id\"), \"inner\")\n  .select(filteredMatchesDF(\"date\"), filteredMatchesDF(\"teams\"), ticketDF(\"match_id\"), ticketDF(\"ticket_price\"))\n\njoinedDF.count()"
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "z.show(joinedDF)"
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "z.show(joinedDF.select($\"match_id\").distinct())"
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "z.show(joinedDF.groupBy($\"date\", $\"teams\", $\"match_id\").agg(min(\"ticket_price\").alias(\"lowest_ticket_price\")))"
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "def getMatchDataByTeams(teams: Array[String], matchDF: org.apache.spark.sql.DataFrame, ticketDF: org.apache.spark.sql.DataFrame): org.apache.spark.sql.DataFrame \u003d {\n    val matchData \u003d matchDF\n      .filter(array_contains($\"teams\", teams(0)) \u0026\u0026 array_contains($\"teams\", teams(1)))\n      \n    val allDF \u003d ticketDF\n      .join(matchData, matchData(\"match_id\") \u003d\u003d\u003d ticketDF(\"match_id\"), \"inner\")\n      .select(ticketDF(\"match_id\"), matchData(\"date\"), matchData(\"time\"), matchData(\"city\"), matchData(\"teams\"), ticketDF(\"ticket_price\"))\n      \n    allDF.groupBy($\"date\", $\"teams\", $\"match_id\", $\"time\", $\"city\").agg(min(\"ticket_price\").alias(\"lowest_ticket_price\"))\n}"
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "val matchCleaned \u003d getMatchDataByTeams(teams, matchDF, ticketDF)\nz.show(matchCleaned)"
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "// part 2: flight data\n\nval airbnbDataDir \u003d \"/user/mjd9571_nyu_edu/project/airbnb_listings_cleaned.csv\"\n\nval flightDataDir \u003d \"/user/zc2398_nyu_edu/flight-data-cleaned/\"\n\nval hotelDataDir \u003d \"/user/yl12081_nyu_edu/project/hotel_data_clean.parquet\"\n\n\nval airbnbDF \u003d spark.read.option(\"header\",\"true\").csv(airbnbDataDir)\nval flightDF \u003d spark.read.parquet(flightDataDir)\nval hotelDF \u003d spark.read.parquet(hotelDataDir)\n"
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "z.show(flightDF)"
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "import org.apache.spark.sql.functions._\n\ndef getAverageFlightPriceDF(inDF:org.apache.spark.sql.DataFrame, flightDF:org.apache.spark.sql.DataFrame) \u003d {\n    val averagePrice \u003d inDF.groupBy(\"arrival_datetime\", \"airline\",\"origin\").agg(round(avg(\"price\"),2).as(\"avg_price\"))\n    val all \u003d inDF.join(averagePrice, Seq(\"arrival_datetime\", \"airline\",\"origin\"),\"left\").drop(\"price\").withColumnRenamed(\"avg_price\",\"price\")\n    // println(all.columns.toList)\n    \n    val allColumnsExceptID \u003d all.columns.filter(_ !\u003d \"id\").toList\n    all.groupBy(allColumnsExceptID.map(col): _*).agg(max(\"id\").as(\"latest_id\"))\n}\n\n\ndef getFlightDataFromMatch(matchData: org.apache.spark.sql.DataFrame) \u003d {\n    val inboundFlightRaw \u003d flightDF.join(matchData, lower(flightDF(\"destination_city\"))\u003d\u003d\u003dmatchData(\"city\") \u0026\u0026 flightDF(\"arrival_datetime\") \u003c matchData(\"time\").minus(expr(\"interval 5 hours\")) \u0026\u0026 flightDF(\"arrival_datetime\") \u003e matchData(\"time\").minus(expr(\"interval 3 days\"))).select(\"arrival_datetime\", \"airline\",\"id\", \"price\", \"city\",\"match_id\",\"teams\",\"origin_city\",\"lowest_ticket_price\").withColumnRenamed(\"origin_city\",\"origin\")\n    val inboundFlight \u003d getAverageFlightPriceDF(inboundFlightRaw, flightDF).withColumnRenamed(\"latest_id\",\"arrival_flight_id\").withColumnRenamed(\"price\",\"in_price\")\n    \n    // inboundFlight\n    val outboundFlightRaw \u003d flightDF.join(matchData, lower(flightDF(\"origin_city\"))\u003d\u003d\u003dmatchData(\"city\") \u0026\u0026 flightDF(\"arrival_datetime\") \u003e matchData(\"time\").plus(expr(\"interval 5 hours\")) \u0026\u0026 flightDF(\"arrival_datetime\") \u003c matchData(\"time\").plus(expr(\"interval 3 days\"))).select(\"departure_datetime\", \"arrival_datetime\",\"airline\",\"id\", \"price\", \"match_id\",\"destination_city\",\"origin_city\").withColumnRenamed(\"destination_city\",\"return_city\").withColumnRenamed(\"origin_city\",\"origin\")\n    \n    val outboundFlight \u003d getAverageFlightPriceDF(outboundFlightRaw, flightDF).withColumnRenamed(\"latest_id\",\"departure_flight_id\").drop(\"arrival_datetime\",\"origin\").withColumnRenamed(\"airline\",\"airline_out\").withColumnRenamed(\"price\",\"out_price\")\n    \n    \n    inboundFlight.join(outboundFlight, inboundFlight(\"match_id\")\u003d\u003d\u003doutboundFlight(\"match_id\") \u0026\u0026 inboundFlight(\"origin\")\u003d\u003d\u003doutboundFlight(\"return_city\"), \"cross\").withColumn(\"flight_price\", col(\"in_price\")+col(\"out_price\")).drop(\"in_price\",\"out_price\",\"return_city\").withColumnRenamed(\"arrival_datetime\",\"arrival_time\").withColumnRenamed(\"departure_datetime\",\"departure_time\")\n}\nz.show(getFlightDataFromMatch(matchCleaned))"
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "val matchFlightsDF \u003d getFlightDataFromMatch(matchCleaned)\nz.show(matchFlightsDF)"
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "//Declared higher up in the code, copied down here for reference.\r\n//val airbnbDataDir \u003d \"/user/mjd9571_nyu_edu/project/airbnb_listings_cleaned.csv\"\r\n//val airbnbDF \u003d spark.read.option(\"header\",\"true\").csv(airbnbDataDir)\r\nairbnbDF.show()"
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "val flightDateDF \u003d matchFlightsDF.withColumn(\"arrival_date\", to_date($\"arrival_time\")).withColumn(\"departure_date\", to_date($\"departure_time\"))\r\nz.show(flightDateDF)"
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "val flightAirbnbJoinDF \u003d flightDateDF.join(\r\n  airbnbDF,\r\n  flightDateDF(\"city\") \u003d\u003d\u003d lower(airbnbDF(\"city\")) \u0026\u0026\r\n  flightDateDF(\"arrival_date\") \u003d\u003d\u003d airbnbDF(\"checkin_date\") \u0026\u0026\r\n  (flightDateDF(\"departure_date\") \u003d\u003d\u003d airbnbDF(\"checkout_date\") ||\r\n   flightDateDF(\"departure_date\") \u003d\u003d\u003d date_add(airbnbDF(\"checkout_date\"), 1))\r\n)\r\nz.show(flightAirbnbJoinDF)"
    }
  ]
}