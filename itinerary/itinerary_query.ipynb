{
  "metadata": {
    "name": "query",
    "kernelspec": {
      "language": "scala",
      "name": "spark2-scala"
    },
    "language_info": {
      "codemirror_mode": "text/x-scala",
      "file_extension": ".scala",
      "mimetype": "text/x-scala",
      "name": "scala",
      "pygments_lexer": "scala"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2,
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "\nimport org.apache.spark.sql.DataFrame\nimport org.apache.spark.sql.functions._"
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "val ticketDataFilePath \u003d \"/user/avk3358_nyu_edu/project/data/ticket-df.parquet\"\nval matchDataFilePath \u003d \"/user/avk3358_nyu_edu/project/data/cleaned-event-df.parquet\"\nval airbnbDataFilePath \u003d \"/user/mjd9571_nyu_edu/project/airbnb_listings_cleaned.csv\"\nval flightDataFilePath \u003d \"/user/zc2398_nyu_edu/flight-data-cleaned/\"\nval hotelDataFilePath \u003d \"/user/yl12081_nyu_edu/hotel_data_clean_refined.parquet\"\n\nval matchDF \u003d spark.read.parquet(matchDataFilePath)\nval ticketDF \u003d spark.read.parquet(ticketDataFilePath)\nval airbnbDF \u003d spark.read.option(\"header\",\"true\").csv(airbnbDataFilePath)\nval flightDF \u003d spark.read.parquet(flightDataFilePath)\nval hotelDF \u003d spark.read.parquet(hotelDataFilePath)"
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "\ndef getMatchesByTeams(teams: Array[String], matchesDF: org.apache.spark.sql.DataFrame): org.apache.spark.sql.DataFrame \u003d {\n    matchesDF\n      .filter(array_contains($\"teams\", teams(0)) \u0026\u0026 array_contains($\"teams\", teams(1)))\n}"
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "\nval teams \u003d Array(\"Real Madrid\", \"Bayern Munich\")\n\nval filteredMatchesDF \u003d getMatchesByTeams(teams, matchDF)\n\nz.show(filteredMatchesDF)"
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "\nval joinedDF \u003d ticketDF\n  .join(filteredMatchesDF, filteredMatchesDF(\"match_id\") \u003d\u003d\u003d ticketDF(\"match_id\"), \"inner\")\n  .select(filteredMatchesDF(\"date\"), filteredMatchesDF(\"teams\"), ticketDF(\"match_id\"), ticketDF(\"ticket_price\"))\n\njoinedDF.count()"
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "\ndef getMatchDataByTeams(teams: Array[String], matchDF: org.apache.spark.sql.DataFrame, ticketDF: org.apache.spark.sql.DataFrame): org.apache.spark.sql.DataFrame \u003d {\n    val matchData \u003d matchDF\n      .filter(array_contains($\"teams\", teams(0)) \u0026\u0026 array_contains($\"teams\", teams(1)))\n      \n    val allDF \u003d ticketDF\n      .join(matchData, matchData(\"match_id\") \u003d\u003d\u003d ticketDF(\"match_id\"), \"inner\")\n      .select(ticketDF(\"match_id\"), matchData(\"date\"), matchData(\"time\"), matchData(\"city\"), matchData(\"teams\"), ticketDF(\"ticket_price\"))\n      \n    allDF.groupBy($\"date\", $\"teams\", $\"match_id\", $\"time\", $\"city\").agg(min(\"ticket_price\").alias(\"lowest_ticket_price\"))\n}"
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "\nval matchCleaned \u003d getMatchDataByTeams(teams, matchDF, ticketDF)\nz.show(matchCleaned)"
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "\n\ndef getAverageFlightPriceDF(inDF:org.apache.spark.sql.DataFrame, flightDF:org.apache.spark.sql.DataFrame) \u003d {\n    val averagePrice \u003d inDF.groupBy(\"arrival_datetime\", \"airline\",\"origin\").agg(round(avg(\"price\"),2).as(\"avg_price\"))\n    val all \u003d inDF.join(averagePrice, Seq(\"arrival_datetime\", \"airline\",\"origin\"),\"left\").drop(\"price\").withColumnRenamed(\"avg_price\",\"price\")\n    // println(all.columns.toList)\n    \n    val allColumnsExceptID \u003d all.columns.filter(_ !\u003d \"id\").toList\n    all.groupBy(allColumnsExceptID.map(col): _*).agg(max(\"id\").as(\"latest_id\"))  // Convert column names to Column type and spread them as arguments\n}\n\n\ndef getFlightDataFromMatch(matchData: org.apache.spark.sql.DataFrame) \u003d {\n    val inboundFlightRaw \u003d flightDF.join(matchData, lower(flightDF(\"destination_city\"))\u003d\u003d\u003dmatchData(\"city\") \u0026\u0026 flightDF(\"arrival_datetime\") \u003c matchData(\"time\").minus(expr(\"interval 5 hours\")) \u0026\u0026 flightDF(\"arrival_datetime\") \u003e matchData(\"time\").minus(expr(\"interval 3 days\"))).select(\"arrival_datetime\", \"airline\",\"id\", \"price\", \"city\",\"match_id\",\"teams\",\"origin_city\",\"lowest_ticket_price\").withColumnRenamed(\"origin_city\",\"origin\")\n    val inboundFlight \u003d getAverageFlightPriceDF(inboundFlightRaw, flightDF).withColumnRenamed(\"latest_id\",\"arrival_flight_id\").withColumnRenamed(\"price\",\"in_price\")\n    \n    // inboundFlight\n    val outboundFlightRaw \u003d flightDF.join(matchData, lower(flightDF(\"origin_city\"))\u003d\u003d\u003dmatchData(\"city\") \u0026\u0026 flightDF(\"arrival_datetime\") \u003e matchData(\"time\").plus(expr(\"interval 5 hours\")) \u0026\u0026 flightDF(\"arrival_datetime\") \u003c matchData(\"time\").plus(expr(\"interval 3 days\"))).select(\"departure_datetime\", \"arrival_datetime\",\"airline\",\"id\", \"price\", \"match_id\",\"destination_city\",\"origin_city\").withColumnRenamed(\"destination_city\",\"return_city\").withColumnRenamed(\"origin_city\",\"origin\")\n    \n    val outboundFlight \u003d getAverageFlightPriceDF(outboundFlightRaw, flightDF).withColumnRenamed(\"latest_id\",\"departure_flight_id\").drop(\"arrival_datetime\",\"origin\").withColumnRenamed(\"airline\",\"airline_out\").withColumnRenamed(\"price\",\"out_price\")\n    \n    \n    inboundFlight.join(outboundFlight, inboundFlight(\"match_id\")\u003d\u003d\u003doutboundFlight(\"match_id\") \u0026\u0026 inboundFlight(\"origin\")\u003d\u003d\u003doutboundFlight(\"return_city\"), \"cross\").withColumn(\"flight_price\", col(\"in_price\")+col(\"out_price\")).drop(\"in_price\",\"out_price\",\"return_city\").withColumnRenamed(\"arrival_datetime\",\"arrival_time\").withColumnRenamed(\"departure_datetime\",\"departure_time\").drop(col(\"outboundFlight.match_id\")).withColumn(\"arrival_date\", $\"arrival_time\".cast(\"date\"))\n        .withColumn(\"departure_date\", $\"departure_time\".cast(\"date\"))\n}\n"
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "\nval flightOutput \u003d getFlightDataFromMatch(matchCleaned)\nz.show(flightOutput)"
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "import org.apache.spark.sql.types.DoubleType\ndef flightJoinWithAirbnb(flightOutput: DataFrame, airbnbDF: DataFrame): DataFrame \u003d {\n  val result \u003d flightOutput.join(\n      airbnbDF.alias(\"a\"),\n      flightOutput(\"city\") \u003d\u003d\u003d lower(airbnbDF(\"city\")) \u0026\u0026\n      flightOutput(\"arrival_date\") \u003d\u003d\u003d airbnbDF(\"checkin_date\") \u0026\u0026\n      (flightOutput(\"departure_date\") \u003d\u003d\u003d airbnbDF(\"checkout_date\") ||\n       flightOutput(\"departure_date\") \u003d\u003d\u003d date_add(airbnbDF(\"checkout_date\"), 1))\n    ).drop(col(\"a.city\")).drop(col(\"a.id\")).drop(col(\"a.listing\")).drop(col(\"a.desc\")).drop(col(\"a.country\")).drop(col(\"a.info_date\"))\n    \n    result.withColumn(\"hotel_price\", col(\"price\").cast(\"double\"))\n          .withColumnRenamed(\"checkin_date\", \"check_in_date\")\n          .withColumnRenamed(\"checkout_date\", \"check_out_date\")\n          .withColumnRenamed(\"unique_id\", \"hotel_id\")\n          .drop(\"price\")\n}"
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "def flightJoinWithHotel(flight: DataFrame, hotel: DataFrame): DataFrame \u003d {\n  val result \u003d flight.alias(\"df1\")\n    .join(\n      hotel.alias(\"df2\"),\n      lower(col(\"df1.city\")) \u003d\u003d\u003d lower(col(\"df2.city\")) \u0026\u0026 \n      col(\"df2.check_in_date\").geq(col(\"df1.arrival_date\")) \u0026\u0026\n      col(\"df2.check_in_date\").leq(date_add(col(\"df1.arrival_date\"), 1)) \u0026\u0026 \n      col(\"df2.check_out_date\") \u003d\u003d\u003d col(\"df1.departure_date\"),\n      \"inner\" \n    ).drop(col(\"df2.city\"))\n    \n    \n  result.drop(\"country\",\"hotel_address\",\"avg_review\",\"square_feet\",\"hotel_info_date\",\"hotel_stay_duration\",\"hotel_name\")\n\n}"
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "val airbnbOutput \u003d flightJoinWithAirbnb(flightOutput, airbnbDF)\nz.show(airbnbOutput)"
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "val agodaOutput \u003d flightJoinWithHotel(flightOutput, hotelDF)\nz.show(agodaOutput)"
    }
  ]
}